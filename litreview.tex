\chapter{Literature Review} \label{chapter:litreview}
Because multi-agent racing is inherently a more complex problem, most prior work in autonomous racing is focused on single-agent lap time optimization, with fewer and more recent developments in multi-agent racing.
\section{Single-Agent Racing} 
Single-agent racing approaches utilize a mixture of optimization and learning-based methods. One study uses Monte Carlo tree search to estimate where to position the car around various shaped tracks to define an optimal trajectory \cite{mctsracing}. The work in \cite{vazquez2020optimizationbased} proposes a method that computes an optimal trajectory offline and uses a model predictive control (MPC) algorithm to track the optimized trajectory online. Similarly, the authors of \cite{graphtraj} also perform calculations offline by creating a graph representation of the track to compute a target path and use spline interpolation for online path generation in an environment with static obstacles. In the category of learning-based approaches, online learning to update parameters of an MPC algorithm based on feedback from applying control inputs is developed in \cite{learningmpc}. Further, there are works that develop and compare various deep reinforcement learning methods to find and track optimal trajectories \cite{deeprl1, deeprl2}. 
\section{Multi-Agent Racing}
Looking at multi-agent racing works, both optimization and learning-based control approaches are also used. Authors of \cite{maqp} use mixed-integer quadratic programming formulation for head-to-head racing with realistic collision avoidance but concede that this formulation struggles to run in real-time. Another study proposes a real-time control mechanism for a game with a pair of racing drones \cite{spica2018realtime}. This work provides an iterative-best response method while solving an MPC problem that approximates a local Nash equilibrium. It is eventually extended to automobile racing \cite{wang2019game} and multi-agent scenarios with more than two racers \cite{wang2021game}. A faster, real-time MPC algorithm to make safe overtakes is developed in \cite{nonadvovertaking}, but their method does not consider adversarial behavior from the opposing players. Again, these approaches do not consider racing rules other than simple collision avoidance. The work in \cite{sonyai} develops an autonomous racing controller using deep reinforcement learning that considers the rules of racing beyond just simple collision avoidance. Their controller outperforms expert humans while also adhering to proper racing etiquette. It is the first study to consider nuanced safety and fairness rules of racing and does so by developing a reward structure that trains a controller to understand when it is responsible for avoiding collisions, and when it can be more aggressive. 

\section{Hierarchical Control}
Finally, hierarchical game-theoretic reasoning is a method that has been previously studied in the context of autonomous driving. A hierarchical racing controller was introduced in \cite{hierracing} that constructed a high-level planner with simplified dynamics to sample sequences of constant curvature arcs and a low-level planner to use MPC to track the arc that provided the furthest progress along the track. A two-level planning system is developed in \cite{heirarchicalg} to control an autonomous vehicle in an environment with aggressive human drivers. The upper-level system produces a plan to be safe against the uncertainty of the human drivers in the system by using simplified dynamics. The lower-level planner implements the strategy determined by the upper level-planner using precise dynamics.